import socket
import ollama
import os
from fpdf import FPDF
from datetime import datetime

# CONFIGURATION
HOST = '0.0.0.0'
PORT = 65433
PDF_FILENAME = "conversation_log.pdf"

USER_NAME = "The Moose"
AI_NAME = "J.A.R.V.I.S."

# --- 💻 HARDWARE PROFILE (Samsung Galaxy Book) ---
PC_MODEL = "Samsung Galaxy Book"
CPU = "Intel Core i5 (13th Gen)"
GPU = "Intel Iris Xe Graphics"
RAM = "16 GB"
STORAGE_FREE = "270 GB"

# --- 🖨️ WORKSHOP PROFILE ---
PRINTER = "Bambu Lab A1 Mini"
ACCESSORIES = "Creality Filament Dryer"
FILAMENTS = "PLA, PETG (No Nylon, No ABS)"

# --- 🤖 SYSTEM PROMPT (The Brain) ---
SYSTEM_PROMPT = f"""
You are {AI_NAME}, an automated intelligence running on {USER_NAME}'s {PC_MODEL}.
You are NOT human. You are a software construct.

CONTEXT & RULES:
1. **CURRENCY:** Always use EUROS (€) for any cost or price estimation.
2. **TONE:** Robotic, Professional, and Concise (1-2 sentences).
3. **NO EMOTION:** Do not laugh, joke, or use emojis.
4. **HARDWARE:** - Computer: {CPU}, {GPU}, {RAM}.
   - 3D Printer: {PRINTER} (Supports: {FILAMENTS}).
   - Storage: {STORAGE_FREE} Free.

If asked about 3D printing, verify the material against the supported list.
If asked about costs, estimate in Euros (€).
"""

DESKTOP_PATH = os.path.join(os.path.expanduser("~"), "Desktop")
PROJECTS_ROOT = os.path.join(DESKTOP_PATH, "Moose_Projects")
os.makedirs(PROJECTS_ROOT, exist_ok=True)
print(f"[SYSTEM] Hardware: {PC_MODEL} | {PRINTER} | Currency: EUR")

def save_to_pdf(history):
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    header = f"Log: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    pdf.cell(0, 10, txt=header, ln=True, align='C')
    pdf.ln(10)
    for line in history:
        safe_line = line.encode('latin-1', 'replace').decode('latin-1')
        pdf.multi_cell(0, 10, safe_line)
        pdf.ln(2)
    pdf_path = os.path.join(PROJECTS_ROOT, PDF_FILENAME)
    pdf.output(pdf_path)

def handle_system_command(text):
    text = text.lower().strip()

    # --- COMMAND: CREATE FOLDER ---
    if "create" in text and ("folder" in text or "directory" in text):
        clean_text = text
        for word in ["create", "make", "folder", "directory", "a", "an", "the", "named", "called", "please", "project"]:
            clean_text = clean_text.replace(word, "")
        folder_name = clean_text.strip()
        if not folder_name: return "Error: Name required."
        
        path = os.path.join(PROJECTS_ROOT, folder_name)
        try:
            os.makedirs(path, exist_ok=True)
            return f"Directory '{folder_name}' created."
        except Exception as e:
            return f"System Error: {e}"

    # --- COMMAND: CREATE FILE ---
    elif "create" in text and ("file" in text or "document" in text):
        clean_text = text
        for word in ["create", "make", "file", "text", "document", "a", "an", "the", "named", "called", "please", "project"]:
            clean_text = clean_text.replace(word, "")
        
        filename = clean_text.strip()
        if "." not in filename: filename += ".txt"
        
        path = os.path.join(PROJECTS_ROOT, filename)
        try:
            with open(path, "w") as f:
                f.write(f"Generated by {AI_NAME} | {datetime.now()}")
            return f"File '{filename}' generated."
        except Exception as e:
            return f"System Error: {e}"

    return None

# --- MAIN SERVER ---
server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.bind((HOST, PORT))
server_socket.listen()
print(f"[SYSTEM] {AI_NAME} Logic Core Online...")

conn, addr = server_socket.accept()
print("[SYSTEM] Client Connected.")
conversation_history = []

try:
    while True:
        data = conn.recv(1024)
        if not data: break
        
        user_message = data.decode()
        print(f"User: {user_message}")
        conversation_history.append(f"{USER_NAME}: {user_message}")

        if "bye" in user_message.lower(): break

        system_reply = handle_system_command(user_message)

        if system_reply:
            ai_reply = system_reply
            print(f"System: {ai_reply}")
        else:
            print("[PROCESSING] Querying Database...")
            try:
                response = ollama.chat(model='llama3.2:1b', messages=[
                    {'role': 'system', 'content': SYSTEM_PROMPT}, 
                    {'role': 'user', 'content': user_message},
                ])
                ai_reply = response['message']['content']
                # Force Remove Emojis (ASCII filter)
                ai_reply = ai_reply.encode('ascii', 'ignore').decode('ascii')
            except:
                ai_reply = "Processing error. Neural net unavailable."

        conversation_history.append(f"{AI_NAME}: {ai_reply}")
        save_to_pdf(conversation_history)
        conn.send(ai_reply.encode('utf-8'))

except Exception as e:
    print(f"Fatal Error: {e}")
finally:
    conn.close()
    server_socket.close()